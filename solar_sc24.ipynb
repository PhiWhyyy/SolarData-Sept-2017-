{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19npgc6iRrdXydpI-2NF-lVK4auyCdK5c",
      "authorship_tag": "ABX9TyP3DjKPGEMwp2uoItCyJrCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhiWhyyy/SolarData-Sept-2017-/blob/main/solar_sc24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Memory-efficient data loading and preprocessing\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Use low_memory to reduce initial memory load\n",
        "    df = pd.read_excel(file_path, engine='openpyxl', low_memory=True)\n",
        "\n",
        "    # Print initial dataset info\n",
        "    print(\"Initial Dataset Info:\")\n",
        "    print(f\"Original Shape: {df.shape}\")\n",
        "    print(\"\\nColumn Types:\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "    # Remove columns with high missing values\n",
        "    threshold = 0.7  # Remove columns with more than 70% missing values\n",
        "    df = df.dropna(thresh=len(df) * (1 - threshold), axis=1)\n",
        "\n",
        "    # Convert memory-heavy columns to more efficient types\n",
        "    for col in df.select_dtypes(include=['float64']).columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
        "\n",
        "    for col in df.select_dtypes(include=['int64']).columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast='integer')\n",
        "\n",
        "    # Handle categorical columns\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        # Convert to category type to reduce memory\n",
        "        df[col] = df[col].astype('category')\n",
        "\n",
        "    return df\n",
        "\n",
        "def prepare_model_data(df):\n",
        "    # Identify target column (adjust as needed)\n",
        "    # Assuming 'Column45' is your target variable\n",
        "    target_column = 'Column45'\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Encode categorical features\n",
        "    categorical_cols = X.select_dtypes(include=['category', 'object']).columns\n",
        "    le = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "    # Feature selection to reduce dimensions\n",
        "    selector = SelectKBest(f_classif, k=min(20, X.shape[1]))\n",
        "    X = selector.fit_transform(X, y)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def train_model(X, y):\n",
        "    # Split the data with stratification\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    # Memory-efficient Random Forest\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,  # Reduced number of trees\n",
        "        max_depth=10,      # Limit tree depth\n",
        "        random_state=42,\n",
        "        n_jobs=-1,         # Use all available cores\n",
        "        max_features='sqrt'# Reduce features considered at each split\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "    print(\"\\nModel Evaluation:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_val, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # File path - ensure this is correct\n",
        "    file_path = r\"/content/Solar Data Sept 2017.xlsx\"\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess data\n",
        "        df = load_and_preprocess_data(file_path)\n",
        "\n",
        "        # Prepare data for modeling\n",
        "        X, y = prepare_model_data(df)\n",
        "\n",
        "        # Train and evaluate model\n",
        "        model = train_model(X, y)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\")\n",
        "        print(e)\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tgxY7KW-Un3E",
        "outputId": "91998b72-2648-4db8-befd-7921e859203d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred:\n",
            "read_excel() got an unexpected keyword argument 'low_memory'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-6-f1a2f6441130>\", line 99, in main\n",
            "    df = load_and_preprocess_data(file_path)\n",
            "  File \"<ipython-input-6-f1a2f6441130>\", line 12, in load_and_preprocess_data\n",
            "    df = pd.read_excel(file_path, engine='openpyxl', low_memory=True)\n",
            "TypeError: read_excel() got an unexpected keyword argument 'low_memory'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load Excel file without the low_memory argument\n",
        "    df = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "    # Print initial dataset info\n",
        "    print(\"Initial Dataset Info:\")\n",
        "    print(f\"Original Shape: {df.shape}\")\n",
        "    print(\"\\nColumn Types:\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "    # Remove columns with high missing values\n",
        "    threshold = 0.7  # Remove columns with more than 70% missing values\n",
        "    df = df.dropna(thresh=len(df) * (1 - threshold), axis=1)\n",
        "\n",
        "    # Convert memory-heavy columns to more efficient types\n",
        "    for col in df.select_dtypes(include=['float64']).columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
        "\n",
        "    for col in df.select_dtypes(include=['int64']).columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast='integer')\n",
        "\n",
        "    # Handle categorical columns\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        # Convert to category type to reduce memory\n",
        "        df[col] = df[col].astype('category')\n",
        "\n",
        "    return df\n",
        "\n",
        "def prepare_model_data(df):\n",
        "    # Identify target column (adjust as needed)\n",
        "    # Assuming 'Column45' is your target variable\n",
        "    target_column = 'Column45'\n",
        "\n",
        "    # Check if target column exists\n",
        "    if target_column not in df.columns:\n",
        "        print(\"Available columns:\", list(df.columns))\n",
        "        raise ValueError(f\"Target column '{target_column}' not found in the DataFrame\")\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Encode categorical features\n",
        "    categorical_cols = X.select_dtypes(include=['category', 'object']).columns\n",
        "    le = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "    # Feature selection to reduce dimensions\n",
        "    selector = SelectKBest(f_classif, k=min(20, X.shape[1]))\n",
        "    X = selector.fit_transform(X, y)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def train_model(X, y):\n",
        "    # Split the data with stratification\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    # Memory-efficient Random Forest\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,  # Reduced number of trees\n",
        "        max_depth=10,      # Limit tree depth\n",
        "        random_state=42,\n",
        "        n_jobs=-1,         # Use all available cores\n",
        "        max_features='sqrt'# Reduce features considered at each split\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "    print(\"\\nModel Evaluation:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_val, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # File path - ensure this is correct\n",
        "    file_path = r\"/content/Solar Data Sept 2017.xlsx\"\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess data\n",
        "        df = load_and_preprocess_data(file_path)\n",
        "\n",
        "        # Prepare data for modeling\n",
        "        X, y = prepare_model_data(df)\n",
        "\n",
        "        # Train and evaluate model\n",
        "        model = train_model(X, y)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\")\n",
        "        print(e)\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "rqYouXXskMQ5",
        "outputId": "e210696b-e116-4594-f466-b2f790d96171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset Info:\n",
            "Original Shape: (21602, 177)\n",
            "\n",
            "Column Types:\n",
            "Column1      object\n",
            "Column2      object\n",
            "Column3      object\n",
            "Column4      object\n",
            "Column5      object\n",
            "              ...  \n",
            "Column173    object\n",
            "Column174    object\n",
            "Column175    object\n",
            "Column176    object\n",
            "Column177    object\n",
            "Length: 177, dtype: object\n",
            "An error occurred:\n",
            "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-7-732110948fb4>\", line 109, in main\n",
            "    model = train_model(X, y)\n",
            "  File \"<ipython-input-7-732110948fb4>\", line 66, in train_model\n",
            "    X_train, X_val, y_train, y_val = train_test_split(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\", line 2806, in train_test_split\n",
            "    train, test = next(cv.split(X=arrays[0], y=stratify))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\", line 1843, in split\n",
            "    for train, test in self._iter_indices(X, y, groups):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\", line 2252, in _iter_indices\n",
            "    raise ValueError(\n",
            "ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load Excel file\n",
        "    df = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "    print(\"Initial Dataset Info:\")\n",
        "    print(f\"Original Shape: {df.shape}\")\n",
        "\n",
        "    # Detailed column type and missing value analysis\n",
        "    print(\"\\nColumn Types and Non-Null Counts:\")\n",
        "    print(df.info())\n",
        "\n",
        "    # Remove columns with too many missing values\n",
        "    df = df.dropna(thresh=len(df) * 0.5, axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def prepare_model_data(df):\n",
        "    # Determine target column (you may need to adjust this)\n",
        "    # Typically, the last column is used as the target\n",
        "    target_column = df.columns[-1]\n",
        "\n",
        "    print(f\"\\nUsing {target_column} as target variable\")\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Encode categorical features\n",
        "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        # Only encode if column has multiple unique values\n",
        "        unique_values = X[col].nunique()\n",
        "        if unique_values > 1:\n",
        "            X[col] = le.fit_transform(X[col].astype(str))\n",
        "        else:\n",
        "            print(f\"Dropping column {col} due to insufficient unique values\")\n",
        "            X = X.drop(columns=[col])\n",
        "\n",
        "    # Encode target variable\n",
        "    y = le.fit_transform(y.astype(str))\n",
        "\n",
        "    # Check class distribution\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    print(\"\\nTarget Variable Distribution:\")\n",
        "    for u, c in zip(unique, counts):\n",
        "        print(f\"Class {u}: {c} samples\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def train_model(X, y):\n",
        "    # Handling extremely imbalanced data\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(y),\n",
        "        y=y\n",
        "    )\n",
        "    class_weight_dict = dict(zip(np.unique(y), class_weights))\n",
        "\n",
        "    # Split data with adjusted stratification\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    # Reduce dimensionality if needed\n",
        "    from sklearn.decomposition import PCA\n",
        "    pca = PCA(n_components=min(20, X.shape[1]))\n",
        "    X_train_reduced = pca.fit_transform(X_train)\n",
        "    X_val_reduced = pca.transform(X_val)\n",
        "\n",
        "    # Memory-efficient Random Forest with class weights\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        random_state=42,\n",
        "        class_weight=class_weight_dict,\n",
        "        n_jobs=-1,\n",
        "        max_features='sqrt'\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_reduced, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_val_reduced)\n",
        "\n",
        "    print(\"\\nModel Evaluation:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_val, y_pred))\n",
        "\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # File path\n",
        "    file_path = r\"/content/Solar Data Sept 2017.xlsx\"\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess data\n",
        "        df = load_and_preprocess_data(file_path)\n",
        "\n",
        "        # Prepare data for modeling\n",
        "        X, y = prepare_model_data(df)\n",
        "\n",
        "        # Train and evaluate model\n",
        "        model = train_model(X, y)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\")\n",
        "        print(e)\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "diZQjLnZPeQp",
        "outputId": "a9ec90e3-5e64-4fa8-a96e-1db41fb1d077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset Info:\n",
            "Original Shape: (21602, 177)\n",
            "\n",
            "Column Types and Non-Null Counts:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21602 entries, 0 to 21601\n",
            "Columns: 177 entries, Column1 to Column177\n",
            "dtypes: object(177)\n",
            "memory usage: 29.2+ MB\n",
            "None\n",
            "\n",
            "Using Column177 as target variable\n",
            "\n",
            "Target Variable Distribution:\n",
            "Class 0: 1 samples\n",
            "Class 1: 21599 samples\n",
            "Class 2: 1 samples\n",
            "Class 3: 1 samples\n",
            "An error occurred:\n",
            "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-8-57e9a5e5eb06>\", line 120, in main\n",
            "    model = train_model(X, y)\n",
            "  File \"<ipython-input-8-57e9a5e5eb06>\", line 72, in train_model\n",
            "    X_train, X_val, y_train, y_val = train_test_split(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\", line 2806, in train_test_split\n",
            "    train, test = next(cv.split(X=arrays[0], y=stratify))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\", line 1843, in split\n",
            "    for train, test in self._iter_indices(X, y, groups):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\", line 2252, in _iter_indices\n",
            "    raise ValueError(\n",
            "ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJsvHwtrit5C",
        "outputId": "e1335e73-a34a-4b32-fadc-2ae0b576b1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hMe8YsAUiuR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ipywidgets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE-JGPBkjGL1",
        "outputId": "9af349ec-14c4-4b9c-f701-b1658eca87e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = r\"/content/Solar Data Sept 2017.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqR-iApCjLLs",
        "outputId": "eb94d38d-d5ad-4ab1-9bea-bb15800ea220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       Column1               Column2  \\\n",
            "0                                        query                 T_REC   \n",
            "1                                       string                  time   \n",
            "2                                           %s                    %s   \n",
            "3  aia.lev1_euv_12s[2017-09-19T23:59:59Z][171]  2017-09-19T23:59:59Z   \n",
            "4  aia.lev1_euv_12s[2017-09-19T23:59:59Z][211]  2017-09-19T23:59:59Z   \n",
            "\n",
            "                   Column3   Column4               Column5    Column6  \\\n",
            "0                    T_OBS  WAVELNTH                  DATE        FSN   \n",
            "1                      TBD       int                  time        int   \n",
            "2                      TBD        %d                    %s         %d   \n",
            "3  2017-09-20T00:00:10.35Z       171  2017-09-26T14:05:10Z  158488054   \n",
            "4  2017-09-19T23:59:59.07Z       211  2017-09-25T14:17:16Z  158488047   \n",
            "\n",
            "    Column7     Column8       Column9  Column10  ... Column168 Column169  \\\n",
            "0   EXPTIME     QUALITY        ORIGIN  TELESCOP  ...   AGT2SVZ   AGT3SVY   \n",
            "1    double         int           TBD       TBD  ...       TBD       TBD   \n",
            "2        %f      0x%08x           TBD       TBD  ...       TBD       TBD   \n",
            "3  2.000171  0x00000000  SDO/JSOC-SDP   SDO/AIA  ...       -14        -3   \n",
            "4  2.900801  0x00000000  SDO/JSOC-SDP   SDO/AIA  ...       -15         0   \n",
            "\n",
            "  Column170 Column171 Column172 Column173  \\\n",
            "0   AGT3SVZ   AGT4SVY   AGT4SVZ  AIMGSHEN   \n",
            "1       TBD       TBD       TBD       TBD   \n",
            "2       TBD       TBD       TBD       TBD   \n",
            "3        -1        58       124        13   \n",
            "4        -1        61       123         4   \n",
            "\n",
            "                                           Column174 Column175   Column176  \\\n",
            "0                                           KEYWDDOC   LVL_NUM  T_REC_step   \n",
            "1                                                TBD       TBD      double   \n",
            "2                                                TBD       TBD          %f   \n",
            "3  https://www.lmsal.com/sdodocs/doc?cmd=dcur&pro...  1.000000   12.000000   \n",
            "4  https://www.lmsal.com/sdodocs/doc?cmd=dcur&pro...  1.000000   12.000000   \n",
            "\n",
            "                 Column177  \n",
            "0              T_REC_epoch  \n",
            "1                     time  \n",
            "2                       %s  \n",
            "3  1993.01.01_00:00:04_TAI  \n",
            "4  1993.01.01_00:00:04_TAI  \n",
            "\n",
            "[5 rows x 177 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "QVxEfg_gj91l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/Solar Data Sept 2017.xlsx\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llnIxg6Fjhjj",
        "outputId": "7b9d0ec8-88f1-46e0-847a-47440590b07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Column1', 'Column2', 'Column3', 'Column4', 'Column5', 'Column6',\n",
            "       'Column7', 'Column8', 'Column9', 'Column10',\n",
            "       ...\n",
            "       'Column168', 'Column169', 'Column170', 'Column171', 'Column172',\n",
            "       'Column173', 'Column174', 'Column175', 'Column176', 'Column177'],\n",
            "      dtype='object', length=177)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"Column4\"])  #Preprossesing the data\n",
        "y = df[\"Column45\"]"
      ],
      "metadata": {
        "id": "K-pVI7K-kZbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "t5C-Wm4Cqjg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in X.select_dtypes(include=[\"object\"]).columns:\n",
        "  le = LabelEncoder()\n",
        "  X[column] = le.fit_transform(X[column])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42) #splitting the data"
      ],
      "metadata": {
        "id": "mHENsvJ_pf70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "URXHVn28plsX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}